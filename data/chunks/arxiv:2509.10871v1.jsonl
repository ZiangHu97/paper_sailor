{"id": "arxiv:2509.10871v1:summary", "paper_id": "arxiv:2509.10871v1", "section": "Summary", "page_from": 0, "page_to": 0, "text": "Strategies to improve the predicting performance of Message-Passing\nNeural-Networks for molecular property predictions can be achieved by\nsimplifying how the message is passed and by using descriptors that capture\nmultiple aspects of molecular graphs. In this work, we designed model\narchitectures that achieved state-of-the-art performance, surpassing more\ncomplex models such as those pre-trained on external databases. We assessed\ndataset diversity to complement our performance results, finding that\nstructural diversity influences the need for additional components in our MPNNs\nand feature sets.\n  In most datasets, our best architecture employs bidirectional message-passing\nwith an attention mechanism, applied to a minimalist message formulation that\nexcludes self-perception, highlighting that relatively simpler models, compared\nto classical MPNNs, yield higher class separability. In contrast, we found that\nconvolution normalization factors do not benefit the predictive power in all\nthe datasets tested. This was corroborated in both global and node-level\noutputs. Additionally, we analyzed the influence of both adding spatial\nfeatures and working with 3D graphs, finding that 2D molecular graphs are\nsufficient when complemented with appropriately chosen 3D descriptors. This\napproach not only preserves predictive performance but also reduces\ncomputational cost by over 50%, making it particularly advantageous for\nhigh-throughput screening campaigns."}
